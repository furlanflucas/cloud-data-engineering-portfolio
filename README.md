# 📊 Data & DevOps Portfolio  
**Author:** Lucas Furlan  
**Last Updated:** April 14th, 2025

Welcome to my professional portfolio. With years of experience in cloud infrastructure, DevOps, and data engineering, I’ve built and maintained scalable systems across diverse domains—from fraud detection pipelines to full-stack CI/CD workflows.

This repository highlights a curated selection of projects that demonstrate my technical depth and strategic thinking in **DevOps, automation, real-time data processing**, and **cloud-native architecture**.

---

## 📁 Repository Structure

### ⚙️ DevOps Projects  
Infrastructure automation, monitoring, and deployment pipelines for production-grade environments.

#### 🔹 Core Projects
- **terraform_aws_setup** – Infrastructure as Code using Terraform to provision EC2, RDS, and S3 with versioning, built with modular, reusable patterns.  
- **monitoring_stack** – Cloud-native observability stack featuring Prometheus, Grafana dashboards, and CloudWatch alarms for proactive alerting.  
- **ci_cd_pipeline** – End-to-end CI/CD pipeline using GitHub Actions to build, test, and deploy Docker containers to ECS/EKS environments.

---

### 🧱 Data Engineering Projects  
Robust data pipelines and architecture built for scale, automation, and real-time analytics.

#### 🔹 Beginner Level
- **data_processing_with_python** – Efficient handling and transformation of large datasets using Python.

#### 🔹 Intermediate Level
- **cloud_data_warehouse_for_music_analytics** – Cloud-based data warehousing for large-scale analytics on music streaming platforms.  
- **data-pipelines-with-airflow** – Automated batch pipelines using Apache Airflow.  
- **data_modeling_with_apache_cassandra** – Scalable NoSQL schema design using Apache Cassandra.  

#### 🔹 Advanced Level
- **Geospatial Data Quality Monitor** – Geospatial anomaly detection and real-time visualization for high-integrity map datasets.  
- **Real-Time Fraud Detection with Kafka & Python** – A production-style pipeline that simulates real-time fraud detection using Apache Kafka, Streamlit dashboards, and Python-based feature engineering.  

---

### 🧠 Data Analysis Projects  
Data-driven insights through exploration, visualization, and storytelling.

#### 🔹 Beginner Level
- **carbon_emissions_analysis** – Global emissions trends visualized to uncover environmental impact.  
- **mental_health_analysis** – Analysis of global mental health factors across countries and age groups.  
- **uncovering_the_worlds_oldest_businesses** – Investigating the factors behind business longevity through historical data.  

#### 🔹 Intermediate Level
- **STEDI_Human_Balance_Analytics** – Sensor-based balance data analysis to understand human stability patterns.  
- **international_debt_analysis** – Visual and statistical exploration of debt data across global economies.  

#### 🔹 Advanced Level
- **fraud_detection** – Statistical modeling and ML techniques to detect fraudulent patterns in financial transactions.

---

## 🧠 Technical Focus Areas

### ☁️ Cloud & DevOps
Terraform, Docker, AWS (EC2, S3, Lambda, CloudWatch, RDS), GitHub Actions, ECS/EKS, CI/CD, observability, infrastructure as code, security best practices

### 🔄 Data Engineering
Airflow, Kafka, Spark, S3-based pipelines, event streaming, scalable batch/real-time data architectures

### 📈 Data Analysis & ML
Pandas, SQL, statistical modeling, anomaly detection, Streamlit dashboards, Matplotlib/Seaborn visualizations

---

## 🧭 Navigation

Each project includes a `README.md` with:
- **Overview** – High-level summary and purpose  
- **Architecture** – System design and tools used  
- **Implementation** – Key components, configs, and pipelines  
- **Outcomes** – Business value or technical impact

---

📬 Connect with me at [flucasio.com](https://flucasio.com) (coming soon) or on [LinkedIn](https://linkedin.com/in/furlanflucas).

